持久化
	两种方式RDB AOF
		RDB是按时间点进行内存快照 生成的二进制文件
		AOF是记录每次写操作的日志文件，append_only类型，可以后台重写日志文件(比如INCRBY一百次，重写后直接INCRBY 100即可)
		能完全关掉持久化功能，将redis做缓存用
		可以同时打开RDB AOF功能，重启时用AOF，因为AOF的数据最完整。
		RDB优点
			RDB文件是以时间为节点经过压缩的redis内存快照文件，用来做备份文件非常好
			适合用来做灾后重建，单个的压缩文件很适合做远程传输。
			RDB能最大化redis性能，只需要后台启动一个子进程就可以，子进程会做剩余工作。父进程不会有硬盘IO之类的操作
			相比AOF RDB允许更快的重启大数据集的redis
		RDB缺点
			由于RDB是按时间保存内存快照，redis异常停止工作时，总会丢失最近一段时间(上次快照到现在的)数据。
			RDB经常需要后台启动子进程来保存文件，如果数据量很大这个动作会很耗时，可能会导致redis服务停止响应(几毫秒甚至数秒钟)。而虽然AOF也需要后台启动进程，但可以调整重写日志频率，而不损失任何性能
		AOF优点
			用AOF更durable，能用不同的fsync策略：不fsync，每秒钟fsync，每次查询都fsync。默认配置每秒fsync一次，但是可能会丢失一秒钟的写数据(fsync是由后台线程)。
			AOF是append-only(追加写)，所以突然断电时也不损坏数据。即使aof文件中有写了一半的命令，redis-check-aof功能还是能轻易修复。
			当aof文件过大时，redis能后台自动重写aof文件。重写绝对安全(比如INCRBY一百次，重写后直接INCRBY 100即可)且不影响原aof继续写入。
			aof以很容易理解的方式记录日志，很容易导出，如果你不小心执行了FLUSHALL，只要aof文件没有重写，依然可以恢复数据，只需要停止redis服务，打开aof文件删除FLUSHALL命令，重启redis即可。
		AOF缺点
			通常，同样大小的数据备份AOF文件要大于RDB文件
			通常AOF比RDB慢，这也取决于fsync策略。总体来说，每秒一次fsync，性能还是很好，而关掉fsync，理论上性能应该和RDB一样。但是依然RDB方式更能保证低延迟，即使在大量写入情况下。
			在恢复数据时，虽然测试足够严格而且至今没有发现Bug，但aof依然是有可能出现bug的(必然的)。但RDB是快照绝对不会有bug。
	该用那种方式
		如果想要redis的数据安全性和PostgreSQL一个级别，应该RDB AOF两种方式一起配合使用
		如果在灾难情况下能接受几分钟的数据损失，可以只使用RDB。
		不鼓励单纯使用aof做备份，因为1)rdb以时间为节点做备份很好 2)rdb重启更快 3)aof不能排除出现bug的可能
		PS：由于以上原因，redis官方表示很可能将RDB AOF两种方式结合起来出现一种持久化模式，但这是长久计划，短期内呵呵……。
	快照Snapshotting
		redis将快照二进制文件默认保存在dump.rdb中，可以在配置文件中配置具体保存策略，或者可以通过SAVE or BGSAVE命令手动保存。
		如何工作：每当需要保存快照文件时，redis fork一个子进程，子进程向临时RDB文件中写数据，写完新的RDB文件后替换老文件。这种方式允许写时复制。
	AOF文件Append-only file
		快照方式连续性(durable)不是特别好,突然断电/kill -9最新的数据

	不小心操作了flushall/flushdb
		解决方案：赶紧shutdown nosave 删掉aof文件中最后的flush命令

	通过rdb文件拷贝一个redis库
		直接拷贝rdb文件，将新库的rdb打开并将rdb文件指向拷贝后的文件，启动redis通过文件恢复即可
		
	redis-check-rdb工具 检查rdb文件是否损坏
		root@josh-ubuntu:/usr/local/redis-4.0.8# redis-check-rdb ./rdb/dump6380.rdb 
		[offset 0] Checking RDB file ./rdb/dump6380.rdb
		[offset 26] AUX FIELD redis-ver = '4.0.8'
		[offset 40] AUX FIELD redis-bits = '64'
		[offset 52] AUX FIELD ctime = '1521738904'
		[offset 67] AUX FIELD used-mem = '1917088'
		[offset 85] AUX FIELD repl-stream-db = '0'
		[offset 135] AUX FIELD repl-id = '458f25b39165943d2e0f0cd7d98e254372d3f335'
		[offset 151] AUX FIELD repl-offset = '3193'
		[offset 167] AUX FIELD aof-preamble = '0'
		[offset 169] Selecting DB ID 0
		[offset 196] Checksum OK
		[offset 196] \o/ RDB looks OK! \o/
		[info] 2 keys read
		[info] 0 expires
		[info] 0 already expired
	
搭建redis集群
	两种方式
		1/ 
			master--slave1
						|
						---slave2
		2/ 
			master--slave1--slave2

	搭建
		第一种方式
			master配置
				关闭rdb(由slave来备份)
					注释掉三个save即可
					#save 900 1
					#save 300 10
					#save 60 10000
				开启aof
					appendonly yes
				路径 放在安装目录的persist下
					dir ./persist
				配置密码(可选)
					################################## SECURITY ###################################
					requirepass **********

			slave配置
				声明slave-of
					slaveof localhost 6379
				配置密码(可选) 在REPLICATION下
					################################# REPLICATION #################################
					masterauth ********** #填入master的密码
				某个slave开启rdb功能
					6380开启rdb
				配置是否只读
					slave-read-only yes
				开启rdb修改rdb文件名和路径
					dir ./persist
					dbfilename dump6381.rdb
					dbfilename dump6380.rdb
				关闭aof功能 修改aof文件名
					appendonly no
					appendfilename "appendonly6380.aof"
					appendfilename "appendonly6381.aof"
			
			启动三台服务器
					redis-server redis.conf
					redis-server redis6380.conf
					redis-server redis6381.conf
			测试
				127.0.0.1:6379> set foo bar
				OK
				127.0.0.1:6380> keys *
				1) "foo"
				127.0.0.1:6381> get foo
				"bar"
				127.0.0.1:6381> set title hha
				(error) READONLY You can't write against a read only slave.
				
				OK
				要注意,虽然6379和6381都禁止了rdb功能，但依然生成了对应的rbd文件,但仔细看文件时间(如下)会发现dump6381.rdb和dump.rdb是相同时间生成的，我猜应该是6380执行的rdb工作，另外两台服务器只是将文件拷贝过去
					root@joshua-ubuntu:/usr/local/redis-4.0.8# ll persist/
					total 28
					drwxr-xr-x 2 root root 4096 Mar 22 17:40 ./
					drwxrwxr-x 7 root root 4096 Mar 22 17:39 ../
					-rw-r--r-- 1 root root   54 Mar 22 17:28 appendonly.aof
					-rw-r--r-- 1 root root  401 Mar 22 17:43 appendonly-test.aof
					-rw-r--r-- 1 root root  189 Mar 22 17:28 dump6380.rdb
					-rw-r--r-- 1 root root  189 Mar 22 17:29 dump6381.rdb
					-rw-r--r-- 1 root root  189 Mar 22 17:29 dump.rdb
				那如果配置三个服务器的rdb文件同名会不会拷贝呢，试一下
					1/ 单台服务器测试关闭rdb功能后是不会生成rdb文件的
					2/ 现在将三台服务器的rdb文件都改为dump.rdb,但只有6380开启rbd功能，执行一些写入操作，结果如下：
						root@joshua-ubuntu:/usr/local/redis-4.0.8# ll persist/
						total 20
						drwxr-xr-x 2 root root 4096 Mar 22 17:56 ./
						drwxrwxr-x 7 root root 4096 Mar 22 17:53 ../
						-rw-r--r-- 1 root root  368 Mar 22 17:57 appendonly.aof
						-rw-r--r-- 1 root root  401 Mar 22 17:43 appendonly-test.aof
						-rw-r--r-- 1 root root  189 Mar 22 17:56 dump.rdb
						root@joshua-ubuntu:/usr/local/redis-4.0.8#
				结论：这种简单集群环境下，各服务器rdb文件保持相同即可，不然会造成不必要的带宽浪费
			缺陷：
				每次slave断开后(无论主动断开还是网络异常)，再次连接master时都要master全部dump出rdb文件再aof，所以多台slave不要一下都启动起来
	集群其他配置项
		################################# REPLICATION #################################
		slave-priority 100 # 从机级别数字小级别高,在主机死掉的时候级别最高的代替主机,0：不允许做主机
		slave-serve-stale-data yes/no # slave和master断开时,是否允许用旧数据响应请求,数据可能已过期
		min-slaves-to-write 3 # 少于3台从服务器时，主机禁止写入
		min-slaves-max-lag 10 # 延迟超过10秒时，主机禁止写入


Sentinel-官方提供的高可用解决方案
	Monitoring：监控功能，Sentinel不断检查主从服务器是否正常工作
	Notification：通知功能，如果Sentinel监控的redis实例出现问题，Sentinel能通知系统管理员 另一个电脑程序等
	Automatic failover：自动失效备援功能，如果主服务器出现问题，Sentinel自动将一台从服务器变为主服务器，并且将其他从服务器配置到新主服务器，并通知应用服务新的服务地址。
	Configuration provider：配置提供者(这么说太费解),简单说就是Sentinel告知客户端当前master服务器地址，如果发生失效备援，sentinel告知客户端新的地址。
	
	天生支持分布式，分布式sentinel的好处：
		1/ 减少误报,需要多台sentinel判定master宕机
		2/ 更健壮，即使有Sentinel停止工作，依然能提供服务
	
	配置Sentinel
		redis自带了一个sentinel配置sentinel.conf，一个典型的最小配置如下：
			sentinel monitor mymaster 127.0.0.1 6379 2
			sentinel down-after-milliseconds mymaster 60000
			sentinel failover-timeout mymaster 180000
			sentinel parallel-syncs mymaster 1

			sentinel monitor resque 192.168.1.3 6380 4
			sentinel down-after-milliseconds resque 10000
			sentinel failover-timeout resque 180000
			sentinel parallel-syncs resque 5
		你只需要将master指定给sentinel即可，每个master一个不同的名字，不需要指定slave(自动识别)，sentinel会自动更新配置(附带slave信息)，每次slave提升为master 每次发现新的sentinel都会重写配置信息。
		
		示例：配置一个简单redis集群通过一台sentinel进行监控，手动杀掉master看sentinel故障迁移效果. 参考文档：http://doc.redisfans.com/topic/sentinel.html
				集群服务器分别为: 6379 6380 6381，其中6380为master另外两台为slave，配置参见“搭建redis集群”
				sentinel配置文件:
					# sentinel monitor <master-name> <ip> <redis-port> <quorum>
					sentinel monitor mymaster localhost 6379 1 # 因为只有一台sentinel,想要看到sentinel故障迁移quorum必须为1
					sentinel down-after-milliseconds mymaster 10000 # 只要服务器在10秒之内能返回一次有效回复，就认为其仍处于正常状态
					# 以上两项配置环境就可以了
			操作：
				1/ 启动三台redis，命令：redis-server redis6380.conf
				2/ 启动sentinel：redis-server sentinel.conf --sentinel
				3/ 检查
					1/状态是否正常
						root@joshua-ubuntu:/usr/local/redis-4.0.8# ps -ef|grep redis
						root       9925      1  0 18:05 ?        00:00:00 redis-server 127.0.0.1:6379
						root       9931      1  0 18:05 ?        00:00:00 redis-server 127.0.0.1:6380
						root       9940      1  0 18:05 ?        00:00:00 redis-server 127.0.0.1:6381
						root       9946   4077  0 18:05 pts/8    00:00:00 redis-server *:26379 [sentinel]
						root       9964   5743  0 18:06 pts/9    00:00:00 grep --color=auto redis
						
					2/查看三台redis的replication信息
						root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6379 info replication
						# Replication
						role:master
						connected_slaves:2
						slave0:ip=127.0.0.1,port=6380,state=online,offset=42,lag=0
						slave1:ip=127.0.0.1,port=6381,state=online,offset=42,lag=0
						master_replid:fbb11fa0e5b5c0682aa9e078abecc4cb6a06d0db
						master_replid2:0000000000000000000000000000000000000000
						master_repl_offset:42
						second_repl_offset:-1
						repl_backlog_active:1
						repl_backlog_size:1048576
						repl_backlog_first_byte_offset:1
						repl_backlog_histlen:42
						
						root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6380 info replication
						# Replication
						role:slave
						master_host:127.0.0.1
						master_port:6379
						master_link_status:up
						master_last_io_seconds_ago:7
						master_sync_in_progress:0
						slave_repl_offset:56
						slave_priority:90
						slave_read_only:1
						connected_slaves:0
						master_replid:fbb11fa0e5b5c0682aa9e078abecc4cb6a06d0db
						master_replid2:0000000000000000000000000000000000000000
						master_repl_offset:56
						second_repl_offset:-1
						repl_backlog_active:1
						repl_backlog_size:1048576
						repl_backlog_first_byte_offset:1
						repl_backlog_histlen:56
						
						root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6381 info replication
						# Replication
						role:slave
						master_host:127.0.0.1
						master_port:6379
						master_link_status:up
						master_last_io_seconds_ago:1
						master_sync_in_progress:0
						slave_repl_offset:70
						slave_priority:100
						slave_read_only:1
						connected_slaves:0
						master_replid:fbb11fa0e5b5c0682aa9e078abecc4cb6a06d0db
						master_replid2:0000000000000000000000000000000000000000
						master_repl_offset:70
						second_repl_offset:-1
						repl_backlog_active:1
						repl_backlog_size:1048576
						repl_backlog_first_byte_offset:1
						repl_backlog_histlen:70
						
						root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 26379 info sentinel
						# Sentinel
						sentinel_masters:1
						sentinel_tilt:0
						sentinel_running_scripts:0
						sentinel_scripts_queue_length:0
						sentinel_simulate_failure_flags:0
						master0:name=mymaster,status=ok,address=127.0.0.1:6379,slaves=2,sentinels=1
				
				4/ 状态OK， 手动停掉6379(redis-cli -p 6379 shutdown) 看sentinel(26379)故障迁移消息
					root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-server sentinel.conf --sentinel
					10516:X 28 Mar 18:32:24.867 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
					10516:X 28 Mar 18:32:24.867 # Redis version=4.0.8, bits=64, commit=00000000, modified=0, pid=10516, just started
					10516:X 28 Mar 18:32:24.867 # Configuration loaded
					10516:X 28 Mar 18:32:24.869 * Increased maximum number of open files to 10032 (it was originally set to 1024).
					                _._                                                  
					           _.-``__ ''-._                                             
					      _.-``    `.  `_.  ''-._           Redis 4.0.8 (00000000/0) 64 bit
					  .-`` .-```.  ```\/    _.,_ ''-._                                   
					 (    '      ,       .-`  | `,    )     Running in sentinel mode
					 |`-._`-...-` __...-.``-._|'` _.-'|     Port: 26379
					 |    `-._   `._    /     _.-'    |     PID: 10516
					  `-._    `-._  `-./  _.-'    _.-'                                   
					 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
					 |    `-._`-._        _.-'_.-'    |           http://redis.io        
					  `-._    `-._`-.__.-'_.-'    _.-'                                   
					 |`-._`-._    `-.__.-'    _.-'_.-'|                                  
					 |    `-._`-._        _.-'_.-'    |                                  
					  `-._    `-._`-.__.-'_.-'    _.-'                                   
					      `-._    `-.__.-'    _.-'                                       
					          `-._        _.-'                                           
					              `-.__.-'                                               

					10516:X 28 Mar 18:32:24.872 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.
					10516:X 28 Mar 18:32:24.876 # Sentinel ID is b10301d9665ffac7336da33548d522a9d1365a84
					10516:X 28 Mar 18:32:24.876 # +monitor master mymaster 127.0.0.1 6379 quorum 1
					10516:X 28 Mar 18:32:24.878 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:32:24.882 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6379


					123^H^H^H^H

					10516:X 28 Mar 18:40:55.993 # +sdown master mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:55.994 # +odown master mymaster 127.0.0.1 6379 #quorum 1/1
					10516:X 28 Mar 18:40:55.997 # +new-epoch 1
					10516:X 28 Mar 18:40:55.997 # +try-failover master mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.003 # +vote-for-leader b10301d9665ffac7336da33548d522a9d1365a84 1
					10516:X 28 Mar 18:40:56.004 # +elected-leader master mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.004 # +failover-state-select-slave master mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.094 # +selected-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.094 * +failover-state-send-slaveof-noone slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.179 * +failover-state-wait-promotion slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.343 # +promoted-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.344 # +failover-state-reconf-slaves master mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:56.383 * +slave-reconf-sent slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:57.331 * +slave-reconf-inprog slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:57.332 * +slave-reconf-done slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:57.394 # +failover-end master mymaster 127.0.0.1 6379
					10516:X 28 Mar 18:40:57.395 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 6380
					10516:X 28 Mar 18:40:57.396 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ mymaster 127.0.0.1 6380
					10516:X 28 Mar 18:40:57.396 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6380
					10516:X 28 Mar 18:41:07.411 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6380
					
					# 整理一下shutdown 6379 后，sentinel(26379)大概做了什么
						1/ sentinel sdown 6379. 主观下线（Subjectively Down， 简称 SDOWN）指的是单个 Sentinel 实例对服务器做出的下线判断
						2/ 几乎同时 sentinel odown 6379. 客观下线（Objectively Down， 简称 ODOWN）指的是多个 Sentinel 实例在对同一个服务器做出 SDOWN 判断， 并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后， 得出的服务器下线判断。 （一个 Sentinel 可以通过向另一个 Sentinel 发送 SENTINEL is-master-down-by-addr 命令来询问对方是否认为给定的服务器已下线。）
							因为只有一台sentinel且配置(# sentinel monitor <master-name> <ip> <redis-port> <quorum>)中quorum=1。
						3/ try-failover尝试故障迁移
						4/ vote-for-leader 投票选出进行故障迁移的机器
						下边是sentinel进行具体故障迁移的步骤
						5/ failover-state-send-slaveof-noone # 6380设置slaveof-noone
						6/ promoted-slave slave 127.0.0.1:6380 # 提升6380为master
						7/ failover-state-reconf-slaves master mymaster # 重新配置mymaster
						8/ slave-reconf-sent slave 127.0.0.1:6381 # 6381配置为6380的slave
						9/ switch-master mymaster 127.0.0.1 6379 127.0.0.1 6380 # mymaster的master 6379-->6380
						10/ 6379 6381 配置为6380的slave
						11/ sdown 6379
					
					此时可以再查看下info sentinel 
						root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 26379 info sentinel
						# Sentinel
						sentinel_masters:1
						sentinel_tilt:0
						sentinel_running_scripts:0
						sentinel_scripts_queue_length:0
						sentinel_simulate_failure_flags:0
						master0:name=mymaster,status=ok,address=127.0.0.1:6380,slaves=2,sentinels=1
						mymaster已经变为127.0.0.1:6380
					
					也可以看各redis的replication信息进行验证
					root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6380 info replication
					# Replication
					role:master
					connected_slaves:1
					slave0:ip=127.0.0.1,port=6381,state=online,offset=35627,lag=0
					master_replid:a834dcb1318d021ef56af81d777b1c35341dfdf4
					master_replid2:fbb11fa0e5b5c0682aa9e078abecc4cb6a06d0db
					master_repl_offset:35627
					second_repl_offset:33169
					repl_backlog_active:1
					repl_backlog_size:1048576
					repl_backlog_first_byte_offset:1
					repl_backlog_histlen:35627
					root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6381 info replication
					# Replication
					role:slave
					master_host:127.0.0.1
					master_port:6380
					master_link_status:up
					master_last_io_seconds_ago:2
					master_sync_in_progress:0
					slave_repl_offset:36040
					slave_priority:100
					slave_read_only:1
					connected_slaves:0
					master_replid:a834dcb1318d021ef56af81d777b1c35341dfdf4
					master_replid2:fbb11fa0e5b5c0682aa9e078abecc4cb6a06d0db
					master_repl_offset:36040
					second_repl_offset:33169
					repl_backlog_active:1
					repl_backlog_size:1048576
					repl_backlog_first_byte_offset:1
					repl_backlog_histlen:36040
					root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6379 info replication
					Could not connect to Redis at 127.0.0.1:6379: Connection refused
					
					重新启动6379 会发现6379变为6380的slave
						10516:X 28 Mar 19:05:01.635 * +convert-to-slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6380
					注意看一下redis的配置文件，会发现配置文件已经更改，这里不展开了
					
			sentinel间通信
				被sentinel管理的redis都接收sentinel的"__sentinel__:hello", sentinel每秒钟发送一次消息
				root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6379 PUBSUB CHANNELS 
				1) "__sentinel__:hello"
				root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6380 PUBSUB CHANNELS 
				1) "__sentinel__:hello"
				root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli -p 6381 PUBSUB CHANNELS 
				1) "__sentinel__:hello"
				root@joshua-ubuntu:/usr/local/redis-4.0.8# redis-cli
				127.0.0.1:6379> SUBSCRIBE __sentinel__:hello
				Reading messages... (press Ctrl-C to quit)
				1) "subscribe"
				2) "__sentinel__:hello"
				3) (integer) 1
				1) "message"
				2) "__sentinel__:hello"
				3) "127.0.0.1,26379,b10301d9665ffac7336da33548d522a9d1365a84,1,mymaster,127.0.0.1,6380,1"
				1) "message"
				2) "__sentinel__:hello"
				3) "127.0.0.1,26379,b10301d9665ffac7336da33548d522a9d1365a84,1,mymaster,127.0.0.1,6380,1"
				1) "message"
				2) "__sentinel__:hello"
				3) "127.0.0.1,26379,b10301d9665ffac7336da33548d522a9d1365a84,1,mymaster,127.0.0.1,6380,1"
				1) "message"
				2) "__sentinel__:hello"
				3) "127.0.0.1,26379,b10301d9665ffac7336da33548d522a9d1365a84,1,mymaster,127.0.0.1,6380,1"
				1) "message"
				2) "__sentinel__:hello"
				3) "127.0.0.1,26379,b10301d9665ffac7336da33548d522a9d1365a84,1,mymaster,127.0.0.1,6380,1"
			sentinel API
			
key设计原则
	例子：书和书签问题
		书签系统
		create table book (
		bookid int,
		title char(20)
		)engine myisam charset utf8;
		--有以下几本书
		insert into book values 
		(5 , 'PHP圣经'),
		(6 , 'ruby实战'),
		(7 , 'mysql运维')
		(8, 'ruby服务端编程');

		create table tags (
		tid int,
		bookid int,
		content char(20)
		)engine myisam charset utf8;
		
		--有以下几个书签
		insert into tags values 
		(10 , 5 , 'PHP'),
		(11 , 5 , 'WEB'),
		(12 , 6 , 'WEB'),
		(13 , 6 , 'ruby'),
		(14 , 7 , 'database'),
		(15 , 8 , 'ruby'),
		(16 , 8 , 'server');

		# 求：既有web标签,又有PHP,同时还标签的书,要用连接查询,比较麻烦
			select * from tags inner join tags as t on tags.bookid=t.bookid
			where tags.content='PHP' and t.content='WEB';

		# 换成key-value存储,会简单很多
			set book:5:title 'PHP sj'
			set book:6:title 'ruby sz'
			set book:7:title 'mysql yw'
			set book:8:title 'ruby server'

			sadd tag:PHP 5
			sadd tag:WEB 5 6
			sadd tag:database 7
			sadd tag:ruby 6 8
			sadd tag:SERVER 8

		查: 既有PHP,又有WEB的书
			127.0.0.1:6381> SINTER tag:PHP tag:WEB
			1) "5"

		查: 有PHP或有WEB标签的书
			127.0.0.1:6381> SUNION tag:PHP tag:WEB
			1) "5"
			2) "6"

		查:含有ruby,不含WEB标签的书
			127.0.0.1:6381> SDIFF tag:ruby tag:WEB
			1) "8"
		关系型数据库转换为kv存储常用原则
			1: 把表名转换为key前缀,如:"tag:"
			2: 第2段放置用于区分区key的字段--对应mysql中的主键的列名,如userid
			3: 第3段放置主键值,如2,3,4...., a , b ,c
			4: 第4段,写要存储的列名
			(5: value为具体username的值)
			举例：用户表 user  , 转换为key-value存储
				userid		username		password		email
				  9				  LiSi			 1111111		lisi@163.com
				set user:userid:9:username LiSi
				set user:userid:9:password 1111111
				set user:userid:9:email lisi@163.com
			PS 无底洞效应
			
			问题: 上述user表,如果需要查询username='lisi'的用户,需要怎么做?
				如果以上述形式存储,只能找出所有user:userid:[id]:username信息,如下
					user:userid:1:username
					……
					user:userid:10000:username
				然后依次遍历,找出lisi,这种方式肯定是不行的。解决方案,以username建立冗余信息,即:
					user:username:zhangsan:userid 1
					……
					user:username:lisi:userid 9
					然后通过两次查询:
						1. 通过get user:username:lisi:userid 获取lisi的userid
						2. 通过get user:userid:9*获取lisi用户信息
			

Jedis

	import redis.clients.jedis.Jedis;
	 
	public class RedisTest {
	    public static void main(String[] args) {
	        //连接本地的 Redis 服务
	        Jedis jedis = new Jedis("192.168.***.***");
	        System.out.println("连接成功");
	        //查看服务是否运行
	        System.out.println("服务正在运行: "+jedis.ping());
	    }
	}
	开始时报 Connection refused: connect
	解决方式
		1/ 将bind 127.0.0.1 改为实际IP(也可以将bind配置完全注释掉,则能接受所有)
			 bind 192.168.***.***
			 redis默认只允许本机连接,所以默认bind 127.0.0.1
		2/ protected-mode 由yes改为no
			实际生产中肯定不能用这种方式啦
		
	微博项目实战
		功能：
			注册
				1/ 接收参数,判断合法性(两次密码是否一致，用户名是否合法)
				2/ 连接redis,查询用户名是否存在,存在提示已占用
				3/ 写入redis,完成登录操作
			登录
			
Redis 集群
	1、集群设计
		Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接
	2、特点：
		1)所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。
		2)节点的fail是通过集群中超过半数的节点检测失效时才生效。
		3)客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。
		4)redis-cluster把所有的物理节点映射到[0-16383]slot上（不一定是平均分配）,cluster 负责维护node<->slot<->value。
		5)Redis集群预分好16384个桶，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384的值，决定将一个key放到哪个桶中
	
	3、搭建具体操作
		集群中至少应该有奇数个节点，所以至少有三个节点，每个节点至少有一个备份节点，所以下面使用6节点
		1)创建目录 cluster/7000 cluster/7001 cluster/7002 cluster/7003 cluster/7004 cluster/7005 
		2)每个目录下拷贝一份redis.conf配置文件
		3)对应修改配置文件:
			daemonize yes #后台启动
			port 7000 #修改端口号，从7000到7005
			cluster-enabled yes #开启cluster
			cluster-config-file nodes-7000.conf
			cluster-node-timeout 5000 #节点5秒钟后连接不上，会被集群认为故障
			appendonly yes #开启aof
		4)拷贝src/redis-trib.rb 至cluster目录下
		5)安装ruby环境
			1 # apt install ruby
			2 # apt-get install rubygems
			3 # wget https://rubygems.global.ssl.fastly.net/gems/redis-3.2.2.gem
			  # gem install redis-3.2.2.gem
		6)创建集群
			1 # ./redis-trib.rb create --replicas 1 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 127.0.0.1:7006
				命令的意义如下：
					给定 redis-trib.rb 程序的命令是 create ， 这表示我们希望创建一个新的集群。
					选项 --replicas 1 表示我们希望为集群中的每个主节点创建一个从节点。
					之后跟着的其他参数则是实例的地址列表， 我们希望程序使用这些地址所指示的实例来创建新集群。
				简单来说， 以上命令的意思就是让 redis-trib 程序创建一个包含三个主节点和三个从节点的集群
			
			2 接着redis-trib 会打印出一份预想中的配置给你看， 如果你觉得没问题的话， 就可以输入 yes ， redis-trib 就会将这份配置应用到集群当中
				-------------------------------------------------------------
				root@josh-ubuntu:/usr/local/redis-4.0.8/cluster# ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005
				>>> Creating cluster
				>>> Performing hash slots allocation on 6 nodes...
				Using 3 masters:
				127.0.0.1:7000
				127.0.0.1:7001
				127.0.0.1:7002
				Adding replica 127.0.0.1:7004 to 127.0.0.1:7000
				Adding replica 127.0.0.1:7005 to 127.0.0.1:7001
				Adding replica 127.0.0.1:7003 to 127.0.0.1:7002
				>>> Trying to optimize slaves allocation for anti-affinity
				[WARNING] Some slaves are in the same host as their master
				M: 3739dd73a559627aeadb19e14826edf0ecb77230 127.0.0.1:7000
				   slots:0-5460 (5461 slots) master
				M: 11e6c87ed32aecdbf1c26e11945018bbfbdac508 127.0.0.1:7001
				   slots:5461-10922 (5462 slots) master
				M: 651df59d5f3c11c12708e599e63b3f7556458e0d 127.0.0.1:7002
				   slots:10923-16383 (5461 slots) master
				S: 79da4a04ffa828155aa4ffdb27fdab000c3996db 127.0.0.1:7003
				   replicates 651df59d5f3c11c12708e599e63b3f7556458e0d
				S: 2c03adff19706e771bc5fd93367587b5ae34d59c 127.0.0.1:7004
				   replicates 3739dd73a559627aeadb19e14826edf0ecb77230
				S: acd7694a60e9a09b8a4366b5f0364201fdd20799 127.0.0.1:7005
				   replicates 11e6c87ed32aecdbf1c26e11945018bbfbdac508
				Can I set the above configuration? (type 'yes' to accept): yes
				-------------------------------------------------------------
			3 输入 yes 并按下回车确认之后， 集群就会将配置应用到各个节点， 并连接起（join）各个节点 —— 也即是， 让各个节点开始互相通讯
				-------------------------------------------------------------
				>>> Nodes configuration updated
				>>> Assign a different config epoch to each node
				>>> Sending CLUSTER MEET messages to join the cluster
				Waiting for the cluster to join...
				>>> Performing Cluster Check (using node 127.0.0.1:7000)
				M: 3739dd73a559627aeadb19e14826edf0ecb77230 127.0.0.1:7000
				   slots:0-5460 (5461 slots) master
				   1 additional replica(s)
				S: acd7694a60e9a09b8a4366b5f0364201fdd20799 127.0.0.1:7005
				   slots: (0 slots) slave
				   replicates 11e6c87ed32aecdbf1c26e11945018bbfbdac508
				M: 651df59d5f3c11c12708e599e63b3f7556458e0d 127.0.0.1:7002
				   slots:10923-16383 (5461 slots) master
				   1 additional replica(s)
				S: 2c03adff19706e771bc5fd93367587b5ae34d59c 127.0.0.1:7004
				   slots: (0 slots) slave
				   replicates 3739dd73a559627aeadb19e14826edf0ecb77230
				S: 79da4a04ffa828155aa4ffdb27fdab000c3996db 127.0.0.1:7003
				   slots: (0 slots) slave
				   replicates 651df59d5f3c11c12708e599e63b3f7556458e0d
				M: 11e6c87ed32aecdbf1c26e11945018bbfbdac508 127.0.0.1:7001
				   slots:5461-10922 (5462 slots) master
				   1 additional replica(s)
				[OK] All nodes agree about slots configuration.
				>>> Check for open slots...
				>>> Check slots coverage...
				[OK] All 16384 slots covered.
				-------------------------------------------------------------
	4、测试
		1) 登录7000节点, 设置key-value, 被放在7001上, 而且自动重定向到7001节点, 重新登录7000, 获取此key, 自动跳转到7001
			joshua@josh-ubuntu:~$ redis-cli -c -p 7000
			127.0.0.1:7000> set name joshua
			-> Redirected to slot [5798] located at 127.0.0.1:7001
			OK
			127.0.0.1:7001> get name
			"joshua"
			127.0.0.1:7001> quit
			joshua@josh-ubuntu:~$ redis-cli -c -p 7000
			127.0.0.1:7000> get name
			-> Redirected to slot [5798] located at 127.0.0.1:7001
			"joshua"
			127.0.0.1:7001>